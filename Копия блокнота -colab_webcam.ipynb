{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QnC7lV7oVFk5OZCm75fqbLAfD9qBy9bw","timestamp":1674708114951}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jzRKNe1iSlNW"},"source":["# Google Colab: Access Webcam for Images and Video\n","This notebook will go through how to access and run code on images and video taken using your webcam.  \n","\n","For this purpose of this tutorial we will be using OpenCV's Haar Cascade to do face detection on our Webcam image and video."]},{"cell_type":"code","metadata":{"id":"Fj9YcAnsT4B_","executionInfo":{"status":"ok","timestamp":1678040200919,"user_tz":-180,"elapsed":7304,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"481e5e8b-5b34-44a7-e5c2-4a9b32f0501d"},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","!pip install face_recognition\n","import face_recognition\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, \\\n","Dropout, BatchNormalization\n","\n","import pathlib\n","from pathlib import Path\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from tensorflow.keras.applications.vgg19 import preprocess_input"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: face_recognition in /usr/local/lib/python3.8/dist-packages (1.3.0)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.8/dist-packages (from face_recognition) (19.24.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from face_recognition) (8.1.3)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from face_recognition) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from face_recognition) (8.4.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"L6pCmkJrUC9g"},"source":["## Helper Functions\n","Below are a few helper function to make converting between different image data types and formats. "]},{"cell_type":"code","metadata":{"id":"09b_0FAnUa9y","executionInfo":{"status":"ok","timestamp":1678040200920,"user_tz":-180,"elapsed":15,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MaZIOR4WaT64"},"source":["## Haar Cascade Classifier\n","For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model. "]},{"cell_type":"code","metadata":{"id":"ZpA68lTrcvZs","executionInfo":{"status":"ok","timestamp":1678040200921,"user_tz":-180,"elapsed":14,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"source":["# initialize the Haar Cascade face detection model\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghUlAJzKSjFT","executionInfo":{"status":"ok","timestamp":1678040200922,"user_tz":-180,"elapsed":15,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":17,"outputs":[]},{"cell_type":"code","source":["path = Path(\"/content/drive/My Drive/diplom/model_save_ocv/checkpoint_best128_new_DS_24-02.h5\")\n","\n","new_model = tf.keras.models.load_model(path)"],"metadata":{"id":"2qc-SXGfUe1O","executionInfo":{"status":"ok","timestamp":1678040201565,"user_tz":-180,"elapsed":657,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class_names = {0: 'anger',\n"," 1: 'contempt',\n"," 2: 'disgust',\n"," 3: 'fear',\n"," 4: 'happy',\n"," 5: 'neutral',\n"," 6: 'sad',\n"," 7: 'surprise',\n"," 8: 'uncertain'}"],"metadata":{"id":"1C4flk-mOSBl","executionInfo":{"status":"ok","timestamp":1678040201567,"user_tz":-180,"elapsed":11,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_apW83lRUe7C","executionInfo":{"status":"ok","timestamp":1678040201567,"user_tz":-180,"elapsed":9,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# def emo_det(img_input):\n","#   # image = tf.keras.utils.load_img(file, target_size = (128, 128))\n","#   # input_arr = tf.keras.utils.img_to_array(image)\n","#   input_arr = cv2.resize(img_input, (128,128), interpolation=cv2.INTER_AREA)\n","#   input_arr = preprocess_input(input_arr)\n","#   input_arr = np.array([input_arr])  # Convert single image to a batch.\n","    \n","#   predictions = new_model.predict(input_arr)\n","\n","#   emotion = class_names[np.argmax(predictions)]\n","#   return emotion"],"metadata":{"id":"WwMFRiZ8Ue97","executionInfo":{"status":"ok","timestamp":1678040201568,"user_tz":-180,"elapsed":9,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["\n","\n","class em_model:\n","    def __init__(self, config:str):\n","        self.config = config\n","        self.model = tf.keras.models.load_model(self.config)\n","        # warm-up model on a random sample\n","        self.img_size = 128\n","        sample = tf.random.uniform((1, self.img_size, self.img_size, 3), 0, 1)\n","        self.model(sample)\n","        \n","    def predict_model(self, image):\n","        input_arr = cv2.resize(image, (128,128), interpolation=cv2.INTER_AREA)\n","        input_arr = preprocess_input(input_arr)\n","        input_arr = np.array([input_arr])  # Convert single image to a batch.\n","          \n","        predictions = new_model.predict(input_arr)\n","\n","        emotion = class_names[np.argmax(predictions)]\n","        return emotion\n","\n"],"metadata":{"id":"2HVTNOYPDnqm","executionInfo":{"status":"ok","timestamp":1678040303762,"user_tz":-180,"elapsed":569,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["\n","\n","model_emotion = em_model(path)\n","\n"],"metadata":{"id":"-xEJxUwckHzv","executionInfo":{"status":"ok","timestamp":1678040307877,"user_tz":-180,"elapsed":1731,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["%%capture --no-display\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","    # convert JS response to OpenCV Image\n","    img = js_to_image(js_reply[\"img\"])\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","    face_locations = face_recognition.face_locations(img)\n","    if len(face_locations) >= 1:\n","      for (top, right, bottom, left) in face_locations:\n","        img_box = img[top:bottom, left:right]\n","        bbox_array = cv2.rectangle(bbox_array,(left, top),(right, bottom),(255,0,0),2)\n","        label = model_emotion.predict_model(img_box)\n","        # label = emo_det(img_box)\n","        cv2.putText(bbox_array, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes\n","\n","\n"],"metadata":{"id":"yx4kXmoaUfBA","executionInfo":{"status":"ok","timestamp":1678040336129,"user_tz":-180,"elapsed":26809,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}},"outputId":"a613f376-0b95-42e3-adbe-79ea2613538b","colab":{"base_uri":"https://localhost:8080/","height":877}},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-524496af74e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;31m# start streaming video from webcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvideo_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# label for video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Capturing...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# initialze bounding box to empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-a05efe86d862>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"HMAe8e-5PRDB","executionInfo":{"status":"ok","timestamp":1678040253705,"user_tz":-180,"elapsed":24,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pnQvOD4YPRGU","executionInfo":{"status":"ok","timestamp":1678040253707,"user_tz":-180,"elapsed":20,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":23,"outputs":[]}]}