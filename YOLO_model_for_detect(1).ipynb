{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYuzwXgEnlFC1IGGeVv6So"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**В этом ноутбуке проведем тест обученной модели на детекцию лиц (скачана из https://github.com/akanametov/yolov8-face)**"],"metadata":{"id":"rNfh7z8AIXuE"}},{"cell_type":"code","source":["\n","import os\n","\n","import requests\n","import cv2\n","import matplotlib.pyplot as plt\n","import glob \n","# import random\n","\n","import pickle\n","\n","import pandas as pd\n","import numpy as np\n","\n","# подключение гугл диска\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# скрытие предупреждений\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# тут загрузим библиотеки для распознавания лиц\n","\n","!pip install face_recognition\n","import face_recognition\n","\n","from tqdm import tqdm\n","from PIL import Image, ImageDraw\n","from google.colab.patches import cv2_imshow\n","import pathlib\n","from pathlib import Path\n","\n","!pip install ultralytics\n","from ultralytics import YOLO\n","\n","import itertools\n","import math\n","import warnings\n","!pip install mediapy\n","import mediapy as media\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, \\\n","Dropout, BatchNormalization\n","from tensorflow.keras.applications.vgg19 import preprocess_input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4lT2wx3IRwF","executionInfo":{"status":"ok","timestamp":1680442444313,"user_tz":-180,"elapsed":69628,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}},"outputId":"c82080a8-e3c4-462d-9c5c-e1afc0a06929"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from face_recognition) (1.22.4)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.1.3)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (19.24.1)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=b134f4f6d9145583527d6cf9a5579a8685d78abdba0e09ae3351b0b5023c8378\n","  Stored in directory: /root/.cache/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.59-py3-none-any.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.3/488.3 KB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.4.4)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.65.0)\n","Collecting sentry-sdk\n","  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (0.14.1+cu116)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (5.9.4)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.13.1+cu116)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Installing collected packages: sentry-sdk, thop, ultralytics\n","Successfully installed sentry-sdk-1.18.0 thop-0.1.1.post2209072238 ultralytics-8.0.59\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapy\n","  Downloading mediapy-1.1.6-py3-none-any.whl (24 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from mediapy) (8.4.0)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from mediapy) (7.34.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapy) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapy) (3.7.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (5.7.1)\n","Collecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (67.6.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (2.14.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (3.0.38)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (0.1.6)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->mediapy) (4.4.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (4.39.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (23.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapy) (2.8.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapy) (3.15.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.2.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.16.0)\n","Installing collected packages: jedi, mediapy\n","Successfully installed jedi-0.18.2 mediapy-1.1.6\n"]}]},{"cell_type":"markdown","source":["Загрузим пользовательское видео"],"metadata":{"id":"NQJGLSZuJgUD"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"ra-M7-8hdRzS","executionInfo":{"status":"ok","timestamp":1680442445343,"user_tz":-180,"elapsed":1056,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"outputs":[],"source":["!cp /content/drive/MyDrive/diplom/video_2023-03-28_21-27-12-2.mp4 /content/"]},{"cell_type":"markdown","source":["Загрузим веса модели"],"metadata":{"id":"1niQ_IW4Jjsy"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"HEK7Aal39IDr","executionInfo":{"status":"ok","timestamp":1680442446050,"user_tz":-180,"elapsed":714,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"outputs":[],"source":["!cp /content/drive/MyDrive/diplom/yolov8n-face.pt /content/"]},{"cell_type":"markdown","source":["Ранее обученная модель VGG19 на классификацию эмоций"],"metadata":{"id":"5KXIkwu8Jm5Z"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"UiHWWcS1semv","executionInfo":{"status":"ok","timestamp":1680442446051,"user_tz":-180,"elapsed":17,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"outputs":[],"source":["path = Path(\"/content/drive/My Drive/diplom/model_save_ocv/checkpoint_best128_new_DS_24-02.h5\")"]},{"cell_type":"markdown","source":["Создадим класс для работы VGG19"],"metadata":{"id":"qOZxrMU-Jwe-"}},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680442446052,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"},"user_tz":-180},"id":"RzLW-ny2sesn"},"outputs":[],"source":["\n","class em_model:\n","    def __init__(self, config:str):\n","        self.config = config\n","        self.model = tf.keras.models.load_model(self.config)\n","        # warm-up model on a random sample\n","        self.img_size = 128\n","        sample = tf.random.uniform((1, self.img_size, self.img_size, 3), 0, 1)\n","        self.model(sample)\n","        self.class_names = {0: 'anger',\n","                      1: 'contempt',\n","                      2: 'disgust',\n","                      3: 'fear',\n","                      4: 'happy',\n","                      5: 'neutral',\n","                      6: 'sad',\n","                      7: 'surprise',\n","                      8: 'uncertain'}\n","        \n","    def predict_model(self, image):\n","        input_arr = cv2.resize(image, (128,128), interpolation=cv2.INTER_AREA)\n","        input_arr = preprocess_input(input_arr)\n","        input_arr = np.array([input_arr])  # Convert single image to a batch.\n","          \n","        predictions = self.model.predict(input_arr)\n","\n","        emotion = self.class_names[np.argmax(predictions)]\n","        return emotion"]},{"cell_type":"markdown","source":["Объявление моделей детекции и классификации"],"metadata":{"id":"pSsL76_hJ2dl"}},{"cell_type":"code","source":["model_path = '/content/yolov8n-face.pt'"],"metadata":{"id":"dK6KUMWeJ8i4","executionInfo":{"status":"ok","timestamp":1680442446053,"user_tz":-180,"elapsed":15,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":30396,"status":"ok","timestamp":1680442476436,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"},"user_tz":-180},"id":"fVWZKIEJ9TPc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a21c51a-44df-481c-d2e5-513133a1b17c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING ⚠️ /content/yolov8n-face.pt appears to require 'omegaconf', which is not in ultralytics requirements.\n","AutoInstall will run now for 'omegaconf' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirement \"omegaconf\" not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting omegaconf\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 KB 10.3 MB/s eta 0:00:00\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 KB 16.4 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf) (6.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py): started\n","  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=8aad1f8524ae4445ed2ed07e97977e804ca34caa663978e8a6c28dd36917b0d4\n","  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf\n","Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['omegaconf']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n"]}],"source":["model_emotion = em_model(path)\n","\n","model = YOLO(model_path)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_WvWW9nY9Nr-","executionInfo":{"status":"ok","timestamp":1680442476438,"user_tz":-180,"elapsed":14,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"outputs":[],"source":["video_path = '/content/video_2023-03-28_21-27-12-2.mp4'"]},{"cell_type":"markdown","source":["Вспомогательная функция для парсинга видеофайла"],"metadata":{"id":"nKCuf44LKEkr"}},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip\n","import numpy as np\n","import os\n","from datetime import timedelta"],"metadata":{"id":"9E12qICEGv8R","executionInfo":{"status":"ok","timestamp":1680442476873,"user_tz":-180,"elapsed":446,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# i.e if video of duration 30 seconds, saves 10 frame per second = 300 frames saved in total\n","SAVING_FRAMES_PER_SECOND = 10"],"metadata":{"id":"FedZaBAaGv_U","executionInfo":{"status":"ok","timestamp":1680442476874,"user_tz":-180,"elapsed":13,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def format_timedelta(td):\n","    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05) \n","    omitting microseconds and retaining milliseconds\"\"\"\n","    result = str(td)\n","    try:\n","        result, ms = result.split(\".\")\n","    except ValueError:\n","        return result + \".00\".replace(\":\", \"-\")\n","    ms = int(ms)\n","    ms = round(ms / 1e4)\n","    return f\"{result}.{ms:02}\".replace(\":\", \"-\")"],"metadata":{"id":"q9pw2D3yGwCN","executionInfo":{"status":"ok","timestamp":1680442476875,"user_tz":-180,"elapsed":13,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Функция для отрисовки названия эмоций (чтобы закрашивался фон текста)"],"metadata":{"id":"VSx_-huqKM25"}},{"cell_type":"code","source":["def rect(img,x,y,w,h,text=\"\"):\n","    # cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n","    if text != \"\":\n","      l = len(text)*35\n","      cv2.rectangle(img,(x,y-44),(x+l,y),(0,255,0),-1)\n","      font = cv2.FONT_HERSHEY_SIMPLEX\n","      cv2.putText(img,text,(x,y), font, 2,(0,0,0),2,cv2.LINE_AA)"],"metadata":{"id":"z0_0MIKH3if1","executionInfo":{"status":"ok","timestamp":1680442476876,"user_tz":-180,"elapsed":12,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Функция парсинга - раскладывает кадры сохраняет в отдельную папку и параллельно формирует новый видео файл с распознанными лицами и эмоциями"],"metadata":{"id":"WLHDy-BiKWWf"}},{"cell_type":"code","source":["%%capture --no-display\n","def main(video_file):\n","    SAVING_FRAMES_PER_SECOND = 25\n","    # load the video clip\n","    video_clip = VideoFileClip(video_file)\n","    # make a folder by the name of the video file\n","    filename, _ = os.path.splitext(video_file)\n","    filename += \"-moviepy\"\n","    if not os.path.isdir(filename):\n","        os.mkdir(filename)\n","\n","    height, width, layers = (1080, 1920, 3)\n","    frameSize = (width,height)\n","    out = cv2.VideoWriter('output_video1.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, frameSize) \n","    \n","    \n","    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n","    saving_frames_per_second = min(video_clip.fps, SAVING_FRAMES_PER_SECOND)\n","    # if SAVING_FRAMES_PER_SECOND is set to 0, step is 1/fps, else 1/SAVING_FRAMES_PER_SECOND\n","    step = 1 / video_clip.fps if saving_frames_per_second == 0 else 1 / saving_frames_per_second\n","    # iterate over each possible frame\n","    for current_duration in np.arange(0, video_clip.duration, step):\n","        # format the file name and save it\n","        frame_duration_formatted = format_timedelta(timedelta(seconds=current_duration)).replace(\":\", \"-\")\n","        frame_filename = os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\")\n","        # save the frame with the current duration\n","        video_clip.save_frame(frame_filename, current_duration)\n","\n","        img = cv2.imread(frame_filename)\n","        results = model.predict(source=frame_filename, show=False, save=False, conf=0.25, imgsz=640, line_thickness=1, max_det=1000) \n","        box_array = 0\n","\n","        # count = 0 \n","        img = results[0].orig_img\n","        bxes = results[0].boxes\n","\n","        \n","        for x, y, w, h in bxes.xyxy.tolist():\n","          x, y, w, h = int(x), int(y), int(w), int(h)\n","          # print('bsagas12121',x, y, w, h, frame_count)\n","          img_box = img[y:h, x:w, :]\n","\n","          label = model_emotion.predict_model(img_box);\n","          cv2.rectangle(img,(x, y),(w, h),(255,0,0),5)\n","          rect(img, x, y, w, h, text = label)\n","          \n","\n","\n","        out.write(img) \n","        cv2.imwrite(frame_filename, img)\n","\n","    out.release()\n","\n","\n","\n","\n"],"metadata":{"id":"bQr5JPLhGwFQ","executionInfo":{"status":"ok","timestamp":1680442476877,"user_tz":-180,"elapsed":12,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["main(video_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JmcDwh_DHl_K","executionInfo":{"status":"ok","timestamp":1680442698696,"user_tz":-180,"elapsed":221830,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}},"outputId":"1cb9934f-7ae1-48f4-c2a3-b7d751dc275a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.00.jpg: 384x640 2 faces, 64.5ms\n","Speed: 0.9ms preprocess, 64.5ms inference, 67.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 1s 761ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.04.jpg: 384x640 2 faces, 17.1ms\n","Speed: 0.7ms preprocess, 17.1ms inference, 9.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 224ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.08.jpg: 384x640 2 faces, 17.2ms\n","Speed: 0.6ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.12.jpg: 384x640 2 faces, 48.6ms\n","Speed: 0.7ms preprocess, 48.6ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 107ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.16.jpg: 384x640 2 faces, 22.6ms\n","Speed: 0.6ms preprocess, 22.6ms inference, 10.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 162ms/step\n","1/1 [==============================] - 0s 276ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.20.jpg: 384x640 2 faces, 29.6ms\n","Speed: 0.6ms preprocess, 29.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 744ms/step\n","1/1 [==============================] - 0s 279ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.24.jpg: 384x640 2 faces, 37.5ms\n","Speed: 0.8ms preprocess, 37.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.28.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 268ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.32.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.36.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 236ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.40.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.44.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.48.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 798ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.52.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 216ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.56.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.60.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 288ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.64.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.68.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.72.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 804ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.76.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.80.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.84.jpg: 384x640 2 faces, 17.7ms\n","Speed: 0.6ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.88.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 293ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.92.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-00.96.jpg: 384x640 2 faces, 16.8ms\n","Speed: 0.6ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.00.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 286ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.04.jpg: 384x640 2 faces, 21.9ms\n","Speed: 8.0ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.08.jpg: 384x640 2 faces, 15.5ms\n","Speed: 0.6ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 241ms/step\n","1/1 [==============================] - 0s 34ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.12.jpg: 384x640 2 faces, 16.0ms\n","Speed: 0.6ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.16.jpg: 384x640 2 faces, 12.6ms\n","Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 235ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.20.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.24.jpg: 384x640 2 faces, 13.3ms\n","Speed: 0.5ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.28.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 1s 758ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.32.jpg: 384x640 2 faces, 12.4ms\n","Speed: 0.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.36.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.40.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.44.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 245ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.48.jpg: 384x640 2 faces, 12.8ms\n","Speed: 0.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.52.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.56.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.60.jpg: 384x640 2 faces, 11.9ms\n","Speed: 0.5ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.64.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.68.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.72.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.76.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 829ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.80.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.84.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.88.jpg: 384x640 2 faces, 12.6ms\n","Speed: 0.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.92.jpg: 384x640 2 faces, 15.3ms\n","Speed: 0.5ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-01.96.jpg: 384x640 2 faces, 14.9ms\n","Speed: 0.6ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 1s 776ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.00.jpg: 384x640 2 faces, 16.0ms\n","Speed: 0.6ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 275ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.04.jpg: 384x640 2 faces, 13.7ms\n","Speed: 0.6ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.08.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 1s 720ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.12.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 226ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.16.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.20.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.24.jpg: 384x640 2 faces, 11.5ms\n","Speed: 0.5ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 762ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.28.jpg: 384x640 2 faces, 12.0ms\n","Speed: 0.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 217ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.32.jpg: 384x640 2 faces, 24.6ms\n","Speed: 0.6ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.36.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.40.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 750ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.44.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.48.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.52.jpg: 384x640 2 faces, 12.9ms\n","Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 230ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.56.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.60.jpg: 384x640 2 faces, 11.8ms\n","Speed: 0.5ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.64.jpg: 384x640 2 faces, 14.6ms\n","Speed: 0.5ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 804ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.68.jpg: 384x640 2 faces, 17.8ms\n","Speed: 1.1ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 267ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.72.jpg: 384x640 2 faces, 15.0ms\n","Speed: 0.6ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.76.jpg: 384x640 2 faces, 26.0ms\n","Speed: 0.6ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 769ms/step\n","1/1 [==============================] - 1s 833ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.80.jpg: 384x640 2 faces, 17.1ms\n","Speed: 0.6ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.84.jpg: 384x640 2 faces, 17.1ms\n","Speed: 0.6ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 224ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.88.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.92.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.6ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-02.96.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 826ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.00.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.04.jpg: 384x640 2 faces, 16.4ms\n","Speed: 0.5ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.08.jpg: 384x640 2 faces, 10.5ms\n","Speed: 0.5ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.12.jpg: 384x640 2 faces, 10.3ms\n","Speed: 0.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 804ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.16.jpg: 384x640 2 faces, 12.0ms\n","Speed: 0.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.20.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.6ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.24.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.28.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.32.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.36.jpg: 384x640 2 faces, 12.2ms\n","Speed: 0.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 776ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.40.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.44.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.48.jpg: 384x640 2 faces, 16.2ms\n","Speed: 0.7ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.52.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 751ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.56.jpg: 384x640 2 faces, 14.6ms\n","Speed: 0.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 267ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.60.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.64.jpg: 384x640 2 faces, 15.8ms\n","Speed: 0.7ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.68.jpg: 384x640 2 faces, 15.2ms\n","Speed: 0.6ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.72.jpg: 384x640 2 faces, 15.3ms\n","Speed: 0.6ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 247ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.76.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.80.jpg: 384x640 2 faces, 13.7ms\n","Speed: 0.5ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 318ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.84.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.88.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.92.jpg: 384x640 2 faces, 14.8ms\n","Speed: 0.5ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 801ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-03.96.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 216ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.00.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.04.jpg: 384x640 2 faces, 12.5ms\n","Speed: 0.6ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.08.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 825ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.12.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 227ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.16.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.20.jpg: 384x640 2 faces, 10.3ms\n","Speed: 0.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 100ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.24.jpg: 384x640 2 faces, 43.6ms\n","Speed: 0.6ms preprocess, 43.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.28.jpg: 384x640 2 faces, 17.6ms\n","Speed: 0.6ms preprocess, 17.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.32.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.36.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 821ms/step\n","1/1 [==============================] - 0s 251ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.40.jpg: 384x640 2 faces, 13.5ms\n","Speed: 0.6ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.44.jpg: 384x640 2 faces, 15.4ms\n","Speed: 0.7ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 1s 772ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.48.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 217ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.52.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.56.jpg: 384x640 2 faces, 13.0ms\n","Speed: 0.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.60.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 820ms/step\n","1/1 [==============================] - 0s 283ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.64.jpg: 384x640 2 faces, 15.9ms\n","Speed: 0.5ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.68.jpg: 384x640 2 faces, 11.5ms\n","Speed: 0.6ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.72.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.76.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.80.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.6ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.84.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 204ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.88.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.92.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-04.96.jpg: 384x640 2 faces, 10.3ms\n","Speed: 0.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.00.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.04.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.08.jpg: 384x640 2 faces, 13.1ms\n","Speed: 0.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 216ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.12.jpg: 384x640 2 faces, 14.5ms\n","Speed: 0.6ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.16.jpg: 384x640 2 faces, 15.5ms\n","Speed: 0.6ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 241ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.20.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.24.jpg: 384x640 2 faces, 14.5ms\n","Speed: 0.6ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.28.jpg: 384x640 2 faces, 17.0ms\n","Speed: 0.6ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.32.jpg: 384x640 2 faces, 10.9ms\n","Speed: 1.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.36.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.40.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.44.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.48.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.52.jpg: 384x640 2 faces, 12.0ms\n","Speed: 0.6ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.56.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.60.jpg: 384x640 2 faces, 15.6ms\n","Speed: 0.6ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.64.jpg: 384x640 2 faces, 12.8ms\n","Speed: 0.5ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.68.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.72.jpg: 384x640 2 faces, 10.3ms\n","Speed: 0.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 197ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.76.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.80.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.84.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.88.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.92.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-05.96.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 203ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.00.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.04.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.08.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.12.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.6ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.16.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.20.jpg: 384x640 2 faces, 16.3ms\n","Speed: 0.7ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 39ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.24.jpg: 384x640 2 faces, 14.3ms\n","Speed: 0.6ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.28.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.32.jpg: 384x640 2 faces, 14.8ms\n","Speed: 0.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.36.jpg: 384x640 2 faces, 15.6ms\n","Speed: 0.6ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 818ms/step\n","1/1 [==============================] - 0s 211ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.40.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.6ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.44.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.48.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.6ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.52.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.56.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.60.jpg: 384x640 2 faces, 16.3ms\n","Speed: 0.6ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 276ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.64.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.68.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.72.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.76.jpg: 384x640 2 faces, 10.4ms\n","Speed: 0.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.80.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.84.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 266ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.88.jpg: 384x640 2 faces, 10.0ms\n","Speed: 0.5ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.92.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 244ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-06.96.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.00.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.04.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 838ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.08.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 238ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.12.jpg: 384x640 2 faces, 15.8ms\n","Speed: 0.6ms preprocess, 15.8ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.16.jpg: 384x640 2 faces, 14.3ms\n","Speed: 0.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 1s 790ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.20.jpg: 384x640 2 faces, 14.6ms\n","Speed: 0.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 264ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.24.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.28.jpg: 384x640 2 faces, 13.4ms\n","Speed: 0.6ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 1s 736ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.32.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.6ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 225ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.36.jpg: 384x640 2 faces, 10.5ms\n","Speed: 0.5ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.40.jpg: 384x640 2 faces, 10.1ms\n","Speed: 0.5ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.44.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 795ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.48.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 213ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.52.jpg: 384x640 2 faces, 11.8ms\n","Speed: 0.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.56.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.60.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 1s 729ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.64.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 819ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.68.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.72.jpg: 384x640 2 faces, 15.7ms\n","Speed: 0.5ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.76.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.80.jpg: 384x640 2 faces, 15.5ms\n","Speed: 0.6ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 277ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.84.jpg: 384x640 2 faces, 14.7ms\n","Speed: 0.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.88.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 46ms/step\n","1/1 [==============================] - 1s 744ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.92.jpg: 384x640 2 faces, 15.2ms\n","Speed: 0.7ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 270ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-07.96.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.00.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.04.jpg: 384x640 2 faces, 10.5ms\n","Speed: 0.5ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 1s 719ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.08.jpg: 384x640 2 faces, 12.0ms\n","Speed: 0.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 248ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.12.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.16.jpg: 384x640 2 faces, 12.9ms\n","Speed: 0.5ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 306ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.20.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.24.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.28.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 861ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.32.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 268ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.36.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.40.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.44.jpg: 384x640 2 faces, 11.9ms\n","Speed: 0.5ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 812ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.48.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 35ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.52.jpg: 384x640 2 faces, 16.6ms\n","Speed: 0.6ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 47ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.56.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 273ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.60.jpg: 384x640 2 faces, 14.8ms\n","Speed: 0.6ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.64.jpg: 384x640 2 faces, 13.6ms\n","Speed: 0.6ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.68.jpg: 384x640 2 faces, 14.9ms\n","Speed: 0.6ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.72.jpg: 384x640 2 faces, 12.3ms\n","Speed: 0.6ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 254ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.76.jpg: 384x640 2 faces, 10.4ms\n","Speed: 0.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.80.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 259ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.84.jpg: 384x640 2 faces, 11.5ms\n","Speed: 0.5ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.88.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.92.jpg: 384x640 2 faces, 15.9ms\n","Speed: 0.6ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 1s 848ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-08.96.jpg: 384x640 2 faces, 11.8ms\n","Speed: 0.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 217ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.00.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.04.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.08.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 809ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.12.jpg: 384x640 2 faces, 10.4ms\n","Speed: 0.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 226ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.16.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.20.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.24.jpg: 384x640 2 faces, 12.7ms\n","Speed: 0.8ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 1s 734ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.28.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.32.jpg: 384x640 2 faces, 10.3ms\n","Speed: 0.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.36.jpg: 384x640 2 faces, 15.2ms\n","Speed: 0.6ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.40.jpg: 384x640 2 faces, 15.2ms\n","Speed: 0.6ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.44.jpg: 384x640 2 faces, 14.4ms\n","Speed: 0.6ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 1s 805ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.48.jpg: 384x640 2 faces, 17.2ms\n","Speed: 0.6ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.52.jpg: 384x640 2 faces, 17.4ms\n","Speed: 0.6ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 289ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.56.jpg: 384x640 2 faces, 11.7ms\n","Speed: 0.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.60.jpg: 384x640 2 faces, 11.9ms\n","Speed: 0.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.64.jpg: 384x640 2 faces, 10.5ms\n","Speed: 0.5ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 873ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.68.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.72.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.76.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.80.jpg: 384x640 2 faces, 12.9ms\n","Speed: 0.5ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 806ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.84.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.88.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.92.jpg: 384x640 2 faces, 10.4ms\n","Speed: 0.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 234ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-09.96.jpg: 384x640 2 faces, 10.6ms\n","Speed: 0.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.00.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.04.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 1s 744ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.08.jpg: 384x640 2 faces, 15.3ms\n","Speed: 0.6ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.12.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.16.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 246ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.20.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.24.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.28.jpg: 384x640 2 faces, 14.6ms\n","Speed: 0.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 236ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.32.jpg: 384x640 2 faces, 15.5ms\n","Speed: 0.6ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.36.jpg: 384x640 2 faces, 15.1ms\n","Speed: 0.6ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.40.jpg: 384x640 2 faces, 14.2ms\n","Speed: 0.6ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 294ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.44.jpg: 384x640 2 faces, 25.9ms\n","Speed: 0.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.48.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 285ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.52.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.56.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 213ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.60.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.64.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.68.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 1s 797ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.72.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.76.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.80.jpg: 384x640 2 faces, 12.1ms\n","Speed: 0.5ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.84.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.88.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.92.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.6ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 1s 825ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-10.96.jpg: 384x640 2 faces, 13.2ms\n","Speed: 0.5ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.00.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.04.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.08.jpg: 384x640 2 faces, 10.8ms\n","Speed: 0.5ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 266ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.12.jpg: 384x640 2 faces, 10.4ms\n","Speed: 0.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.16.jpg: 384x640 2 faces, 13.7ms\n","Speed: 0.6ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.20.jpg: 384x640 2 faces, 10.2ms\n","Speed: 0.5ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.24.jpg: 384x640 2 faces, 18.5ms\n","Speed: 0.8ms preprocess, 18.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.28.jpg: 384x640 2 faces, 14.1ms\n","Speed: 0.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 1s 751ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.32.jpg: 384x640 2 faces, 16.0ms\n","Speed: 0.6ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 157ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.36.jpg: 384x640 2 faces, 14.8ms\n","Speed: 0.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.40.jpg: 384x640 2 faces, 13.9ms\n","Speed: 0.6ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 1s 729ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.44.jpg: 384x640 2 faces, 11.3ms\n","Speed: 0.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 224ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.48.jpg: 384x640 2 faces, 11.6ms\n","Speed: 0.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.52.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.56.jpg: 384x640 2 faces, 11.2ms\n","Speed: 0.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 1s 736ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.60.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 257ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.64.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.68.jpg: 384x640 2 faces, 16.5ms\n","Speed: 0.6ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 60ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.72.jpg: 384x640 2 faces, 10.9ms\n","Speed: 0.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 821ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.76.jpg: 384x640 2 faces, 13.1ms\n","Speed: 0.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.80.jpg: 384x640 2 faces, 11.5ms\n","Speed: 0.5ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.84.jpg: 384x640 2 faces, 12.0ms\n","Speed: 0.6ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 224ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.88.jpg: 384x640 2 faces, 11.4ms\n","Speed: 0.6ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.92.jpg: 384x640 2 faces, 10.7ms\n","Speed: 0.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-11.96.jpg: 384x640 2 faces, 11.1ms\n","Speed: 0.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 733ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.00.jpg: 384x640 2 faces, 20.0ms\n","Speed: 0.6ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.04.jpg: 384x640 2 faces, 16.8ms\n","Speed: 0.6ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 278ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.08.jpg: 384x640 2 faces, 14.6ms\n","Speed: 0.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.12.jpg: 384x640 2 faces, 15.5ms\n","Speed: 0.6ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.16.jpg: 384x640 2 faces, 15.1ms\n","Speed: 0.6ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 266ms/step\n","1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.20.jpg: 384x640 2 faces, 14.9ms\n","Speed: 0.6ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.24.jpg: 384x640 2 faces, 18.8ms\n","Speed: 0.6ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.28.jpg: 384x640 2 faces, 11.5ms\n","Speed: 0.5ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","image 1/1 /content/video_2023-03-28_21-27-12-2-moviepy/frame0-00-12.32.jpg: 384x640 2 faces, 11.0ms\n","Speed: 0.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 1s 839ms/step\n"]}]},{"cell_type":"markdown","source":["Сжимаем видео для отображения в ноутбуке"],"metadata":{"id":"XYglAVnUKvGw"}},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n","import os\n","\n","# Input video path\n","save_path = \"/content/output_video1.mp4\"\n","\n","# Compressed video path\n","compressed_path = \"/content/result_compressed.mp4\"\n","\n","os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246,"output_embedded_package_id":"1BvqNKKmVEvIo7qdHvZ1iOOY1MWWtE67L"},"id":"KnY8worYtHju","executionInfo":{"status":"ok","timestamp":1680442769224,"user_tz":-180,"elapsed":70542,"user":{"displayName":"Александр Гомелев","userId":"16740658847247968809"}},"outputId":"2b8fce3a-6f6b-4924-c1d9-6293573c608d"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"al1lfzBQwMiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p4rT1lTJwMk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D3vMgSadwMn-"},"execution_count":null,"outputs":[]}]}